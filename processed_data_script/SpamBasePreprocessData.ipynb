{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents. A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam. Here is one example of such data:\n",
    "\n",
    "Download data from this url\n",
    "- URL: https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil, os\n",
    "import re\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto download if having not downloaded file yet !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare folder\n",
    "if not os.path.exists('../data/uci_spambase'):\n",
    "    os.makedirs('../data/uci_spambase')\n",
    "    \n",
    "if not os.path.exists('../processed_data'):\n",
    "    os.makedirs('../processed_data')\n",
    "    \n",
    "## if there's any errors inside, there's a chance that directories have been created unsuccessfully\n",
    "## please create directories by hand again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found target file\n"
     ]
    }
   ],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/'\n",
    "spambase_target = [\"spambase.data\",\"spambase.names\"]\n",
    "for spambase_i in spambase_target:\n",
    "    spambase_file_content = requests.get(url+spambase_i, allow_redirects=True)\n",
    "    open(spambase_i, 'wb').write(spambase_file_content.content)\n",
    "    shutil.move(spambase_i, os.path.join('../data/uci_spambase', spambase_i))\n",
    "    \n",
    "# create loops for waiting for files (time out: 100 tries)\n",
    "time_out = 1\n",
    "while not os.path.exists('../data/uci_spambase/spambase.data'):\n",
    "    time.sleep(1)\n",
    "    print(\"loading \" + str(time_out), end=' ')\n",
    "    time_out += 1\n",
    "print(\"\\nFound target file\")\n",
    "# while not os.path.exists('../data/uci_spambase/spambase.data'):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If have downloaded, start run here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Using the link mentioned above we will download 2 files i.e \"spambase.data\" and \"spambase.names\".<br> The spambase.data file contains various parameters for each file as well as a classification of spam or not spam (i.e 1 = spam, 0 = Not spam). The spambase.names file contains the descriptions of each of the features. We will extract these features from the file and apply them to the dataset to create models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns: \n",
      " ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'class']\n",
      "Number of columns: \n",
      " 58\n"
     ]
    }
   ],
   "source": [
    "# extract columns from spambase.names file.\n",
    "\n",
    "# created an empty columns list\n",
    "columns = []\n",
    "\n",
    "# open file \n",
    "columns_names_file = open('../data/uci_spambase/spambase.names')\n",
    "# remove '\\n', split the text,  and match with word_freq|char_freq feature \n",
    "for line in columns_names_file:\n",
    "    if not re.match(r'\\|', line):\n",
    "        line = line.rstrip()\n",
    "        if re.search(r'(word_freq_|char_freq_|capital_run_length_).+', line):   \n",
    "            words = line.split()\n",
    "            first_word = words[0]\n",
    "            columns.append(first_word[:-1])\n",
    "#The list of columns in the names file doesn't include the column defined classification of spam or ham (not spam), so let's add one. \n",
    "\n",
    "columns.append('class')\n",
    "print('All columns: \\n',columns)\n",
    "print('Number of columns: \\n',len(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the data from the data file and apply our 'categories' list as the column header. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function which will remove extra leading \n",
    "# and tailing whitespace from the data.\n",
    "# pass dataframe as a parameter here\n",
    "def whitespace_remover(dataframe):\n",
    "    \n",
    "    # iterating over the columns\n",
    "    for i in dataframe.columns:\n",
    "          \n",
    "        # checking datatype of each columns\n",
    "        if dataframe[i].dtype == 'object':\n",
    "              \n",
    "            # applying strip function on column\n",
    "            dataframe[i] = dataframe[i].map(str.strip)\n",
    "        else:\n",
    "              \n",
    "            # if condn. is False then it will do nothing.\n",
    "            pass\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                float64\n",
       "word_freq_address             float64\n",
       "word_freq_all                 float64\n",
       "word_freq_3d                  float64\n",
       "word_freq_our                 float64\n",
       "word_freq_over                float64\n",
       "word_freq_remove              float64\n",
       "word_freq_internet            float64\n",
       "word_freq_order               float64\n",
       "word_freq_mail                float64\n",
       "word_freq_receive             float64\n",
       "word_freq_will                float64\n",
       "word_freq_people              float64\n",
       "word_freq_report              float64\n",
       "word_freq_addresses           float64\n",
       "word_freq_free                float64\n",
       "word_freq_business            float64\n",
       "word_freq_email               float64\n",
       "word_freq_you                 float64\n",
       "word_freq_credit              float64\n",
       "word_freq_your                float64\n",
       "word_freq_font                float64\n",
       "word_freq_000                 float64\n",
       "word_freq_money               float64\n",
       "word_freq_hp                  float64\n",
       "word_freq_hpl                 float64\n",
       "word_freq_george              float64\n",
       "word_freq_650                 float64\n",
       "word_freq_lab                 float64\n",
       "word_freq_labs                float64\n",
       "word_freq_telnet              float64\n",
       "word_freq_857                 float64\n",
       "word_freq_data                float64\n",
       "word_freq_415                 float64\n",
       "word_freq_85                  float64\n",
       "word_freq_technology          float64\n",
       "word_freq_1999                float64\n",
       "word_freq_parts               float64\n",
       "word_freq_pm                  float64\n",
       "word_freq_direct              float64\n",
       "word_freq_cs                  float64\n",
       "word_freq_meeting             float64\n",
       "word_freq_original            float64\n",
       "word_freq_project             float64\n",
       "word_freq_re                  float64\n",
       "word_freq_edu                 float64\n",
       "word_freq_table               float64\n",
       "word_freq_conference          float64\n",
       "char_freq_;                   float64\n",
       "char_freq_(                   float64\n",
       "char_freq_[                   float64\n",
       "char_freq_!                   float64\n",
       "char_freq_$                   float64\n",
       "char_freq_#                   float64\n",
       "capital_run_length_average    float64\n",
       "capital_run_length_longest      int64\n",
       "capital_run_length_total        int64\n",
       "class                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('../data/uci_spambase/spambase.data', header=None)\n",
    "data.columns = columns\n",
    "whitespace_remover(data)\n",
    "data = data.apply(pd.to_numeric)\n",
    "# Check data types\n",
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any trailing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to csv file\n",
    "data.to_csv (r'../processed_data/spambase.csv', index=None)\n",
    "# applying whitespace_remover function on dataframe\n",
    "data = pd.read_csv('../processed_data/spambase.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  class  \n",
       "0                       278      1  \n",
       "1                      1028      1  \n",
       "2                      2259      1  \n",
       "3                       191      1  \n",
       "4                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "4601\n"
     ]
    }
   ],
   "source": [
    "print(len(data.columns))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spam, Non-Spam Breakouts\n",
    "\n",
    "Let' take a look at our dataset ot see how much spam and how much ham (non-spam) we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam: 1813\n",
      "Non-spam: 2788\n"
     ]
    }
   ],
   "source": [
    "# Count spam and non-spam\n",
    "count_spam = len(data[data['class'] == 1])\n",
    "count_nonspam = len(data[data['class'] == 0])\n",
    "\n",
    "print(\"Spam: %d\" %count_spam)\n",
    "print(\"Non-spam: %d\" %count_nonspam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if any column is null \n",
    "data.columns.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
